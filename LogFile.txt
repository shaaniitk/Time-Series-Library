kalki@kalki-gpu:~/Documents/workspace/Time-Series-Library$ python ./scripts/train/train_celestial_production.py
Could not register with unified registry
WARNING:root:Could not import TSNormalizer from utils.normalization
WARNING:root:Wavelet components not available: attempted relative import beyond top-level package
INFO:main:Starting PRODUCTION Celestial Enhanced PGAT training run
INFO:main:Heavy-duty overnight configuration enabled
INFO:main:================================================================================
INFO:main:Memory diagnostics enabled; detailed logs stored at checkpoints/celestial_enhanced_pgat_production_overnight/memory_diagnostics.log
INFO:main:Configuration summary | model=Celestial_Enhanced_PGAT seq_len=250 pred_len=10 d_model=416 n_heads=8 e_layers=4 d_layers=2 train_epochs=50
INFO:main:Optimization summary | batch_size=16 learning_rate=0.001 patience=999 target=log_Open,log_High,log_Low,log_Close target_wave_indices=[0, 1, 2, 3] c_out=4 wave_aggregation=True
INFO:main:Using device: cpu (CPU fallback)
INFO:main:Reproducibility seed configured to 2024
INFO:main:Loading production data modules
INFO:main:Loaded train data module | samples=6750 batches=421 batch_size=16 drop_last=True shuffle=True pin_memory=False prefetch_factor=n/a persistent_workers=False
INFO:main:Loaded val data module | samples=41 batches=3 batch_size=16 drop_last=False shuffle=False pin_memory=False prefetch_factor=n/a persistent_workers=False
INFO:main:Loaded test data module | samples=41 batches=3 batch_size=16 drop_last=False shuffle=False pin_memory=False prefetch_factor=n/a persistent_workers=False
INFO:main:Data loader sizes | train=421 val=3 test=3
INFO:main:Preparing scaling utilities for loss computation
INFO:main:Main scaler detected with 118 features
INFO:main:Target scaler detected with 4 features
INFO:main:Using target indices for OHLC: [0, 1, 2, 3]
INFO:main:Initializing production Celestial Enhanced PGAT model
ğŸ”§ AUTO-CORRECTING INPUT WAVE COUNT:
Configured: 118
Detected from CSV: 113
Using detected value: 113
ğŸ“Š Analyzing CSV with 119 columns...
ğŸ“Š Found 113 celestial columns out of 119 total
âš ï¸ 2 features could not be assigned to celestial bodies:
117: Ascendant_sin
118: Ascendant_cos
âš ï¸ chiron not found in CSV
ğŸ“Š Assigning Ascendant features to Chiron (closest astrological match)

ğŸŒŒ CELESTIAL FEATURE MAPPING REPORT:
ğŸª sun (10 features): [0, 1, 2, 3, 4, 5, 6, 80, 87, 88]
Features: dyn_Sun_sin, dyn_Sun_cos, dyn_Sun_speed ... Sun_sin, Sun_cos
ğŸª moon (10 features): [7, 8, 9, 10, 11, 12, 13, 81, 89, 90]
Features: dyn_Moon_sin, dyn_Moon_cos, dyn_Moon_speed ... Moon_sin, Moon_cos
ğŸª mercury (10 features): [21, 22, 23, 24, 25, 26, 27, 83, 93, 94]
Features: dyn_Mercury_sin, dyn_Mercury_cos, dyn_Mercury_speed ... Mercury_sin, Mercury_cos
ğŸª venus (10 features): [35, 36, 37, 38, 39, 40, 41, 85, 97, 98]
Features: dyn_Venus_sin, dyn_Venus_cos, dyn_Venus_speed ... Venus_sin, Venus_cos
ğŸª mars (10 features): [14, 15, 16, 17, 18, 19, 20, 82, 91, 92]
Features: dyn_Mars_sin, dyn_Mars_cos, dyn_Mars_speed ... Mars_sin, Mars_cos
ğŸª jupiter (10 features): [28, 29, 30, 31, 32, 33, 34, 84, 95, 96]
Features: dyn_Jupiter_sin, dyn_Jupiter_cos, dyn_Jupiter_speed ... Jupiter_sin, Jupiter_cos
ğŸª saturn (10 features): [42, 43, 44, 45, 46, 47, 48, 86, 99, 100]
Features: dyn_Saturn_sin, dyn_Saturn_cos, dyn_Saturn_speed ... Saturn_sin, Saturn_cos
ğŸª uranus ( 9 features): [49, 50, 51, 52, 53, 54, 55, 101, 102]
Features: dyn_Uranus_sin, dyn_Uranus_cos, dyn_Uranus_speed ... Uranus_sin, Uranus_cos
ğŸª neptune ( 9 features): [56, 57, 58, 59, 60, 61, 62, 103, 104]
Features: dyn_Neptune_sin, dyn_Neptune_cos, dyn_Neptune_speed ... Neptune_sin, Neptune_cos
ğŸª pluto ( 9 features): [63, 64, 65, 66, 67, 68, 69, 105, 106]
Features: dyn_Pluto_sin, dyn_Pluto_cos, dyn_Pluto_speed ... Pluto_sin, Pluto_cos
ğŸª north_node ( 7 features): [70, 71, 72, 73, 74, 107, 108]
Features: dyn_Mean Rahu_sin, dyn_Mean Rahu_cos, dyn_Mean Rahu_speed ... Mean Rahu_sin, Mean Rahu_cos
ğŸª south_node ( 7 features): [75, 76, 77, 78, 79, 109, 110]
Features: dyn_Mean Ketu_sin, dyn_Mean Ketu_cos, dyn_Mean Ketu_speed ... Mean Ketu_sin, Mean Ketu_cos
ğŸª chiron ( 2 features): [111, 112]
Features: Ascendant_sin, Ascendant_cos
ğŸ“Š Total celestial features mapped: 113
ğŸ“Š Available celestial columns: 113
ğŸ“Š Total CSV columns: 119
ğŸ“Š Expected input waves: 113
ğŸ“Š Max feature index used: 112
âœ… Celestial mapping validation complete.

ğŸŒŒ Phase-Aware Celestial Processor initialized:

Input waves: 113 (auto-detected)
Celestial bodies: 13
Celestial dimension: 32
Dynamic feature mapping: ENABLED
Assumes phase info already in inputs (sin/cos encoded)
Will compute explicit phase differences for edges
ğŸŒŒ Celestial Wave Aggregator initialized:
Input waves: 118
Celestial bodies: 13
moon: 9 waves
mercury: 9 waves
venus: 9 waves
sun: 9 waves
mars: 9 waves
jupiter: 9 waves
saturn: 9 waves
uranus: 9 waves
neptune: 9 waves
pluto: 9 waves
north_node: 12 waves
south_node: 8 waves
chiron: 3 waves
INFO:models.Celestial_Enhanced_PGAT.Model:Celestial projection preserves: 416D â†’ 416D (1.0x)
INFO:models.Celestial_Enhanced_PGAT.Model:ğŸš€ Initializing Petri Net Combiner with message passing (edge_feature_dim=6, num_steps=2)
INFO:models.Celestial_Enhanced_PGAT.Model:âœ… Petri Net Combiner initialized - memory efficient with ZERO information loss!
INFO:models.Celestial_Enhanced_PGAT.Model:ğŸš€ Using EdgeConditionedGraphAttention - ZERO information loss from edge features!
INFO:models.Celestial_Enhanced_PGAT.Model:ğŸ¯ Target Autocorrelation Module enabled with 2 layers
INFO:models.Celestial_Enhanced_PGAT.Model:ğŸ“… Calendar Effects Module enabled with 104D embeddings
INFO:main:Model initialized successfully
INFO:main:Parameter statistics | total=44,236,621 trainable=44,236,621 approx_size_mb=168.7
INFO:main:Standard precision training
INFO:main:Gradient accumulation configured | steps=2 effective_batch_size=32
INFO:main:Learning rate schedule preview | warmup_epochs=5 base_lr=0.001000 min_lr=0.000001 remaining_epochs=45
INFO:main:Sample learning rates: E1:0.000200, E5:0.001000, E6:0.001000, E26:0.000587, E50:0.000002
INFO:main:Using MSE Loss for deterministic predictions
INFO:main:Early stopping patience configured to 999 (effectively disabled)
INFO:main:Checkpoints will be saved to checkpoints/celestial_enhanced_pgat_production_overnight
INFO:main:Inspecting data file at ./data/prepared_financial_data.csv for target resolution
INFO:main:Feature summary | total_columns=119 feature_columns=118
INFO:main:Estimated CSV row count: 7109
INFO:main:Auto-set enc_in/dec_in to 118 based on feature count
INFO:main:Resolved target indices: [0, 1, 2, 3]
INFO:main:Resolved target names: ['log_Open', 'log_High', 'log_Low', 'log_Close']
INFO:main:Starting production training loop
INFO:main:Configured for 50 training epochs
INFO:main:Epoch 1/50 - production training
ğŸ” MEMORY [FORWARD_START] Input shapes: x_enc=torch.Size([16, 250, 118]), x_dec=torch.Size([16, 135, 118])
CPU Memory: 0.74GB
ğŸ” MEMORY [BEFORE_ENC_EMBEDDING]
CPU Memory: 1.05GB
ğŸ” MEMORY [AFTER_ENC_EMBEDDING] enc_out shape: torch.Size([16, 250, 416])
CPU Memory: 1.10GB
ğŸ” MEMORY [BEFORE_MARKET_CONTEXT]
CPU Memory: 1.13GB
ğŸ” MEMORY [AFTER_MARKET_CONTEXT] market_context shape: torch.Size([16, 250, 416])
CPU Memory: 1.15GB
ğŸ” MEMORY [BEFORE_ADJ_WEIGHT_MLP] market_context: torch.Size([16, 250, 416])
CPU Memory: 4.68GB
ğŸ” MEMORY [AFTER_ADJ_WEIGHT_MLP] weights: torch.Size([16, 250, 3])
CPU Memory: 4.68GB
ğŸ” MEMORY [BEFORE_ADJ_NORMALIZE]
CPU Memory: 4.68GB
ğŸ” MEMORY [AFTER_ADJ_NORMALIZE] phase_norm: torch.Size([16, 250, 13, 13]), astro_norm: torch.Size([16, 250, 13, 13])
CPU Memory: 4.68GB
ğŸ” MEMORY [BEFORE_ADJ_FUSION] Broadcasting torch.Size([16, 250, 1, 1]) with torch.Size([16, 250, 13, 13])
CPU Memory: 4.68GB
ğŸ” MEMORY [AFTER_ADJ_FUSION] combined_phase_adj: torch.Size([16, 250, 13, 13])
CPU Memory: 4.68GB
ğŸ” MEMORY BEFORE celestial_combiner: CPU=4.68GB
ğŸ” INPUT SHAPES to celestial_combiner:
astronomical_adj: torch.Size([16, 250, 13, 13])
learned_adj: torch.Size([16, 250, 13, 13])
dynamic_adj: torch.Size([16, 250, 13, 13])
enc_out: torch.Size([16, 250, 416])
ğŸš€ PETRI NET: Rich edge features preserved!
combined_adj: torch.Size([16, 250, 13, 13])
rich_edge_features: torch.Size([16, 250, 13, 13, 6]) (6D vectors, NO compression!)
Edge features: [theta_diff, phi_diff, velocity_diff, radius_ratio, long_diff, phase_alignment]
âœ… MEMORY AFTER celestial_combiner: CPU=13.06GB
ğŸ“Š MEMORY DELTA: CPU=+8.38GB
âœ… OUTPUT SHAPES from celestial_combiner:
combined_adj: torch.Size([16, 250, 13, 13])
fusion_metadata keys: ['astronomical_contribution', 'learned_contribution', 'attention_contribution', 'edge_feature_dim', 'num_message_passing_steps', 'avg_transition_strength', 'final_edge_density', 'temporal_edge_variance', 'spatial_edge_variance', 'node_state_norm', 'rich_edge_features_shape', 'edge_features_preserved', 'no_compression']
ğŸ§¹ AFTER GC: CPU=13.06GB
ğŸ” STEP 6: Hierarchical mapping check (enabled=False)
ğŸ” STEP 7: Spatiotemporal encoding
enc_out shape: torch.Size([16, 250, 416])
combined_adj shape: torch.Size([16, 250, 13, 13])
â­ï¸ Petri bypass enabled â€” using encoder output directly for graph processing
ğŸ” STEP 8: Graph attention processing
encoded_features shape: torch.Size([16, 250, 416])
use_efficient_covariate_interaction: True
INFO:main:Batch 0/421 | loss=1.283732 elapsed=7.5s
ğŸ” MEMORY [FORWARD_START] Input shapes: x_enc=torch.Size([16, 250, 118]), x_dec=torch.Size([16, 135, 118])
CPU Memory: 11.80GB
ğŸ” MEMORY [BEFORE_ENC_EMBEDDING]
CPU Memory: 11.80GB
ğŸ” MEMORY [AFTER_ENC_EMBEDDING] enc_out shape: torch.Size([16, 250, 416])
CPU Memory: 11.80GB
ğŸ” MEMORY [BEFORE_MARKET_CONTEXT]
CPU Memory: 11.80GB
ğŸ” MEMORY [AFTER_MARKET_CONTEXT] market_context shape: torch.Size([16, 250, 416])
CPU Memory: 11.80GB
ğŸ” MEMORY [BEFORE_ADJ_WEIGHT_MLP] market_context: torch.Size([16, 250, 416])
CPU Memory: 11.80GB
ğŸ” MEMORY [AFTER_ADJ_WEIGHT_MLP] weights: torch.Size([16, 250, 3])
CPU Memory: 11.80GB
ğŸ” MEMORY [BEFORE_ADJ_NORMALIZE]
CPU Memory: 11.80GB
ğŸ” MEMORY [AFTER_ADJ_NORMALIZE] phase_norm: torch.Size([16, 250, 13, 13]), astro_norm: torch.Size([16, 250, 13, 13])
CPU Memory: 11.80GB
ğŸ” MEMORY [BEFORE_ADJ_FUSION] Broadcasting torch.Size([16, 250, 1, 1]) with torch.Size([16, 250, 13, 13])
CPU Memory: 11.80GB
ğŸ” MEMORY [AFTER_ADJ_FUSION] combined_phase_adj: torch.Size([16, 250, 13, 13])
CPU Memory: 11.80GB
ğŸ” MEMORY BEFORE celestial_combiner: CPU=11.80GB
ğŸ” INPUT SHAPES to celestial_combiner:
astronomical_adj: torch.Size([16, 250, 13, 13])
learned_adj: torch.Size([16, 250, 13, 13])
dynamic_adj: torch.Size([16, 250, 13, 13])
enc_out: torch.Size([16, 250, 416])
ğŸš€ PETRI NET: Rich edge features preserved!
combined_adj: torch.Size([16, 250, 13, 13])
rich_edge_features: torch.Size([16, 250, 13, 13, 6]) (6D vectors, NO compression!)
Edge features: [theta_diff, phi_diff, velocity_diff, radius_ratio, long_diff, phase_alignment]
âœ… MEMORY AFTER celestial_combiner: CPU=18.24GB
ğŸ“Š MEMORY DELTA: CPU=+6.44GB
âœ… OUTPUT SHAPES from celestial_combiner:
combined_adj: torch.Size([16, 250, 13, 13])
fusion_metadata keys: ['astronomical_contribution', 'learned_contribution', 'attention_contribution', 'edge_feature_dim', 'num_message_passing_steps', 'avg_transition_strength', 'final_edge_density', 'temporal_edge_variance', 'spatial_edge_variance', 'node_state_norm', 'rich_edge_features_shape', 'edge_features_preserved', 'no_compression']
ğŸ§¹ AFTER GC: CPU=18.24GB
ğŸ” STEP 6: Hierarchical mapping check (enabled=False)
ğŸ” STEP 7: Spatiotemporal encoding
enc_out shape: torch.Size([16, 250, 416])
combined_adj shape: torch.Size([16, 250, 13, 13])
â­ï¸ Petri bypass enabled â€” using encoder output directly for graph processing
ğŸ” STEP 8: Graph attention processing
encoded_features shape: torch.Size([16, 250, 416])
use_efficient_covariate_interaction: True
ğŸ” MEMORY [FORWARD_START] Input shapes: x_enc=torch.Size([16, 250, 118]), x_dec=torch.Size([16, 135, 118])
CPU Memory: 18.24GB
ğŸ” MEMORY [BEFORE_ENC_EMBEDDING]
CPU Memory: 18.24GB
ğŸ” MEMORY [AFTER_ENC_EMBEDDING] enc_out shape: torch.Size([16, 250, 416])
CPU Memory: 18.24GB
ğŸ” MEMORY [BEFORE_MARKET_CONTEXT]
CPU Memory: 18.24GB
ğŸ” MEMORY [AFTER_MARKET_CONTEXT] market_context shape: torch.Size([16, 250, 416])
CPU Memory: 18.24GB
ğŸ” MEMORY [BEFORE_ADJ_WEIGHT_MLP] market_context: torch.Size([16, 250, 416])
CPU Memory: 18.24GB
ğŸ” MEMORY [AFTER_ADJ_WEIGHT_MLP] weights: torch.Size([16, 250, 3])
CPU Memory: 18.24GB