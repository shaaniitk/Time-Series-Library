# Enhanced SOTA PGAT - Scaled Up Configuration
# All enhanced features enabled with larger model dimensions
# Designed for comprehensive evaluation on synthetic data

# Required data configuration
data: custom
root_path: data
data_path: synthetic_multi_wave.csv
target: target_0,target_1,target_2
task_name: long_term_forecast
is_training: 1
model_id: enhanced_pgat_scaled
checkpoints: ./checkpoints/

features: M
freq: H
embed: timeF

# SCALED UP sequence lengths
seq_len: 168      # 1 week of hourly data (vs 96)
label_len: 84     # Half of seq_len (vs 48)  
pred_len: 48      # 2 days prediction (vs 24)

# Input/Output dimensions
enc_in: 12        # Total features in dataset
dec_in: 12
c_out: 3
c_out_evaluation: 3

# SCALED UP model architecture
d_model: 512      # INCREASED from 128 to 512 (4x larger)
n_heads: 16       # INCREASED from 4 to 16 (4x larger)
d_ff: 2048        # INCREASED from 256 to 2048 (8x larger)
dropout: 0.1      # REDUCED from 0.2 for larger model
factor: 3

# Training hyperparameters (adjusted for larger model)
learning_rate: 0.00005   # REDUCED from 0.0001 for stability
lradj: 'type3'
train_epochs: 15         # MORE epochs for complex model
patience: 7              # INCREASED patience
batch_size: 16           # REDUCED from 32 due to memory constraints
num_workers: 2
use_amp: false           # Keep false for stability

# Enhanced regularization for larger model
weight_decay: 5e-4       # INCREASED regularization
gradient_clip_val: 1.0   # INCREASED gradient clipping

# Memory optimization for larger model
enable_memory_optimization: true
memory_chunk_size: 16    # Match batch size

# Enhanced PGAT specific features
model: Enhanced_SOTA_PGAT
num_wave_features: 7

# SCALED UP multi-scale patching
use_multi_scale_patching: true
patch_len: 24            # INCREASED from 16
stride: 12               # INCREASED from 8
num_wave_patch_latents: 64   # INCREASED from 16
num_target_patch_latents: 32 # INCREASED from 8

# ALL ENHANCED FEATURES ENABLED
use_hierarchical_mapper: true
use_attention_temp_to_spatial: true
use_stochastic_learner: true      # ENABLED
use_gated_graph_combiner: true    # ENABLED
enable_dynamic_graph: true
enable_graph_attention: true

# ADVANCED decoder features
use_mixture_density: true         # ENABLED
use_mixture_decoder: true         # ENABLED
mixture_components: 5             # INCREASED from 3
mixture_multivariate_mode: 'independent'

# Enhanced PGAT features
use_dynamic_edge_weights: true
use_adaptive_temporal: true
enable_graph_positional_encoding: true
enable_structural_pos_encoding: true

# Graph learning parameters
base_adjacency_weight: 0.6
adaptive_adjacency_weight: 0.4
adjacency_diagonal_value: 0.05

# ADVANCED loss configuration
loss: mixture                     # Use mixture loss
loss_function_type: mixture
quantile_levels: [0.1, 0.5, 0.9] # Add quantile prediction

# Advanced training features
use_early_stopping: true
monitor_metric: 'val_loss'
save_best_only: true
reduce_lr_on_plateau: true
lr_patience: 3
lr_factor: 0.5
min_lr: 1e-6

# Evaluation settings
evaluate_every_n_epochs: 2
save_predictions: true
compute_metrics: ['mse', 'mae', 'mape']