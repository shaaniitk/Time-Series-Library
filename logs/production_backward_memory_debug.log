2025-10-24 15:58:16,419 INFO __main__.memory: Memory diagnostics enabled | log_interval=25 dump_cuda_summary=False
2025-10-24 15:58:16,420 DEBUG __main__.memory: {"context_use_gpu": "True", "cpu_available_mb": 44325.56, "cpu_total_mb": 62907.12, "cpu_used_mb": 18581.56, "cuda_info": "cuda_unavailable", "process_rss_mb": 531.03, "process_vms_mb": 3925.82, "stage": "device_selection"}
2025-10-24 15:58:16,623 DEBUG __main__.memory: {"context_test_batches": 3.0, "context_train_batches": 421.0, "context_val_batches": 3.0, "cpu_available_mb": 44244.96, "cpu_total_mb": 62907.12, "cpu_used_mb": 18662.16, "cuda_info": "cuda_unavailable", "process_rss_mb": 578.29, "process_vms_mb": 3970.36, "stage": "post_data_module_loading"}
2025-10-24 15:58:16,624 DEBUG __main__.memory: {"context_has_target_scaler": "True", "context_target_indices": "[0, 1, 2, 3]", "cpu_available_mb": 44244.96, "cpu_total_mb": 62907.12, "cpu_used_mb": 18662.16, "cuda_info": "cuda_unavailable", "process_rss_mb": 578.29, "process_vms_mb": 3970.36, "stage": "post_scaler_setup"}
2025-10-24 15:58:16,882 DEBUG __main__.memory: {"context_param_size_mb": 166.09350967407227, "context_total_params": 43540417.0, "context_trainable_params": 43540417.0, "cpu_available_mb": 44079.54, "cpu_total_mb": 62907.12, "cpu_used_mb": 18827.59, "cuda_info": "cuda_unavailable", "process_rss_mb": 750.12, "process_vms_mb": 5215.84, "stage": "post_model_initialization"}
2025-10-24 15:58:16,883 DEBUG __main__.memory: {"stage": "model_dtype_summary", "dtype_counts": {"torch.float32": 764}}
2025-10-24 15:58:16,884 DEBUG __main__.memory: {"context_gradient_accumulation_steps": 2.0, "context_learning_rate": 0.001, "context_weight_decay": 0.0001, "cpu_available_mb": 44079.54, "cpu_total_mb": 62907.12, "cpu_used_mb": 18827.59, "cuda_info": "cuda_unavailable", "process_rss_mb": 750.13, "process_vms_mb": 5215.84, "stage": "post_optimizer_setup"}
2025-10-24 15:58:16,893 DEBUG __main__.memory: {"context_train_batches": 421.0, "context_train_epochs": 50.0, "context_val_batches": 3.0, "cpu_available_mb": 44078.36, "cpu_total_mb": 62907.12, "cpu_used_mb": 18828.76, "cuda_info": "cuda_unavailable", "process_rss_mb": 751.0, "process_vms_mb": 5229.63, "stage": "training_loop_start"}
2025-10-24 15:58:16,895 DEBUG __main__.memory: {"stage": "train_epoch_1_start_model_dtypes", "dtype_summary": {"torch.float32": 764}}
2025-10-24 15:58:16,895 DEBUG __main__.memory: {"context_gradient_accumulation_steps": 2.0, "cpu_available_mb": 44078.36, "cpu_total_mb": 62907.12, "cpu_used_mb": 18828.76, "cuda_info": "cuda_unavailable", "process_rss_mb": 751.01, "process_vms_mb": 5229.63, "stage": "train_epoch_1_start"}
2025-10-24 15:58:16,901 DEBUG __main__.memory: {"stage": "train_epoch_1_batch_1_pre_forward_tensors", "tensors": [{"name": "batch_x", "present": true, "shape": [16, 250, 118], "dtype": "torch.float32", "device": "cpu", "requires_grad": false}, {"name": "batch_y", "present": true, "shape": [16, 135, 118], "dtype": "torch.float32", "device": "cpu", "requires_grad": false}, {"name": "batch_x_mark", "present": true, "shape": [16, 250, 3], "dtype": "torch.float32", "device": "cpu", "requires_grad": false}, {"name": "batch_y_mark", "present": true, "shape": [16, 135, 3], "dtype": "torch.float32", "device": "cpu", "requires_grad": false}, {"name": "dec_inp", "present": true, "shape": [16, 135, 118], "dtype": "torch.float32", "device": "cpu", "requires_grad": false}], "use_amp": false}
2025-10-24 15:58:16,901 DEBUG __main__.memory: {"context_use_amp": "False", "cpu_available_mb": 44068.52, "cpu_total_mb": 62907.12, "cpu_used_mb": 18838.6, "cuda_info": "cuda_unavailable", "process_rss_mb": 761.58, "process_vms_mb": 5229.63, "stage": "train_epoch_1_batch_1_pre_forward"}
