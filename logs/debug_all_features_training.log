2025-10-31 22:24:08,686 INFO __main__: Starting PRODUCTION Celestial Enhanced PGAT training run
2025-10-31 22:24:08,686 INFO __main__: Heavy-duty overnight configuration enabled
2025-10-31 22:24:08,687 INFO __main__: üîç DIAGNOSTIC MODE ENABLED - Writing to training_diagnostic.log
2025-10-31 22:24:08,688 INFO __main__: ================================================================================
2025-10-31 22:24:08,695 INFO __main__: Memory diagnostics enabled; detailed logs stored at checkpoints/celestial_debug_all_features/memory_diagnostics.log
2025-10-31 22:24:08,695 INFO __main__: Configuration summary | model=Celestial_Enhanced_PGAT seq_len=96 pred_len=12 d_model=128 n_heads=8 e_layers=3 d_layers=2 train_epochs=2
2025-10-31 22:24:08,696 INFO __main__: Optimization summary | batch_size=2 learning_rate=0.0001 patience=10 target=log_Open,log_High,log_Low,log_Close target_wave_indices=[0, 1, 2, 3] c_out=4 wave_aggregation=True
2025-10-31 22:24:08,697 INFO __main__: Using device: cpu (CPU fallback)
2025-10-31 22:24:08,720 INFO __main__: Reproducibility seed configured to 42
2025-10-31 22:24:08,721 INFO __main__: Loading production data modules
2025-10-31 22:24:09,476 INFO __main__: Training scalers extracted: main_scaler=True, target_scaler=True
2025-10-31 22:24:09,478 INFO __main__: Loaded train data module | samples=6802 batches=3401 batch_size=2 drop_last=True shuffle=True pin_memory=False prefetch_factor=n/a persistent_workers=False
2025-10-31 22:24:10,246 INFO __main__: Created val dataset with training scalers
2025-10-31 22:24:10,247 INFO __main__: Loaded val data module | samples=139 batches=70 batch_size=2 drop_last=False shuffle=False pin_memory=False prefetch_factor=n/a persistent_workers=False
2025-10-31 22:24:11,065 INFO __main__: Created test dataset with training scalers
2025-10-31 22:24:11,066 INFO __main__: Loaded test data module | samples=39 batches=20 batch_size=2 drop_last=False shuffle=False pin_memory=False prefetch_factor=n/a persistent_workers=False
2025-10-31 22:24:11,066 INFO __main__: Data loader sizes | train=3401 val=70 test=20
2025-10-31 22:24:11,066 INFO __main__: Preparing scaling utilities for loss computation
2025-10-31 22:24:11,066 INFO __main__: Main scaler detected with 118 features
2025-10-31 22:24:11,066 INFO __main__: Target scaler detected with 4 features
2025-10-31 22:24:11,066 INFO __main__: Using target indices for OHLC: [0, 1, 2, 3]
2025-10-31 22:24:11,067 INFO __main__: Initializing production Celestial Enhanced PGAT model
2025-10-31 22:24:11,067 INFO models.Celestial_Enhanced_PGAT_Modular.Model: Initializing Celestial Enhanced PGAT | seq_len=96 pred_len=12 d_model=128 celestial_bodies=13 wave_aggregation=True mixture_decoder=True stochastic_learner=True hierarchical_mapping=True
2025-10-31 22:24:11,069 INFO models.Celestial_Enhanced_PGAT_Modular.Model: Phase-aware aggregation configured | input_waves=118 target_wave_indices=[0, 1, 2, 3]
2025-10-31 22:24:11,369 INFO models.celestial_modules.context_fusion: üåü Initializing Multi-Scale Context Fusion | mode=multi_scale | d_model=128
2025-10-31 22:24:11,369 INFO models.celestial_modules.context_fusion: üìä Multi-scale configuration | short=5 medium=15 long=global dropout=0.100
2025-10-31 22:24:11,373 INFO models.celestial_modules.context_fusion: ‚úÖ Multi-scale fusion layer initialized
2025-10-31 22:24:11,373 INFO models.celestial_modules.context_fusion: ‚ö° Performance: Small overhead (~8% memory increase, fast)
2025-10-31 22:24:11,373 INFO models.celestial_modules.context_fusion: üß† Benefits: Multi-temporal patterns, richest context, gradient flow enhancement
2025-10-31 22:24:11,373 INFO models.celestial_modules.context_fusion: üåä Gradient Flow: Creates shortcuts for long-term dependencies
2025-10-31 22:24:11,374 INFO models.celestial_modules.context_fusion: ‚öñÔ∏è  Bias Mitigation: Balances recent vs historical observations
2025-10-31 22:24:11,374 INFO models.celestial_modules.context_fusion: üîç Temporal Awareness: Provides both local dynamics and global context
2025-10-31 22:24:11,374 INFO models.celestial_modules.context_fusion: üéâ Multi-Scale Context Fusion successfully initialized
2025-10-31 22:24:11,421 ERROR __main__: Model initialization failed: d_model (128) must be divisible by num_graph_nodes (13) for efficient processing.
Traceback (most recent call last):
  File "/Users/shantanumisra/workspace/TSLib/Time-Series-Library/scripts/train/train_celestial_production.py", line 2491, in train_celestial_pgat_production
    model = Model(args).to(device)
            ^^^^^^^^^^^
  File "/Users/shantanumisra/workspace/TSLib/Time-Series-Library/models/Celestial_Enhanced_PGAT_Modular.py", line 92, in __init__
    self.graph_module = GraphModule(self.model_config)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shantanumisra/workspace/TSLib/Time-Series-Library/models/celestial_modules/graph.py", line 118, in __init__
    raise ValueError(f"d_model ({config.d_model}) must be divisible by num_graph_nodes ({config.num_graph_nodes}) for efficient processing.")
ValueError: d_model (128) must be divisible by num_graph_nodes (13) for efficient processing.
2025-10-31 23:22:25,200 INFO __main__: Starting PRODUCTION Celestial Enhanced PGAT training run
2025-10-31 23:22:25,202 INFO __main__: Heavy-duty overnight configuration enabled
2025-10-31 23:22:25,202 INFO __main__: üîç DIAGNOSTIC MODE ENABLED - Writing to training_diagnostic.log
2025-10-31 23:22:25,203 INFO __main__: ================================================================================
2025-10-31 23:22:25,206 INFO __main__: Memory diagnostics enabled; detailed logs stored at checkpoints/celestial_debug_all_features/memory_diagnostics.log
2025-10-31 23:22:25,206 INFO __main__: Configuration summary | model=Celestial_Enhanced_PGAT seq_len=96 pred_len=12 d_model=128 n_heads=8 e_layers=3 d_layers=2 train_epochs=2
2025-10-31 23:22:25,206 INFO __main__: Optimization summary | batch_size=2 learning_rate=0.0001 patience=10 target=log_Open,log_High,log_Low,log_Close target_wave_indices=[0, 1, 2, 3] c_out=4 wave_aggregation=True
2025-10-31 23:22:25,206 INFO __main__: Using device: cpu (CPU fallback)
2025-10-31 23:22:25,215 INFO __main__: Reproducibility seed configured to 42
2025-10-31 23:22:25,218 INFO __main__: Loading production data modules
2025-10-31 23:22:26,579 INFO __main__: Training scalers extracted: main_scaler=True, target_scaler=True
2025-10-31 23:22:26,580 INFO __main__: Loaded train data module | samples=6802 batches=3401 batch_size=2 drop_last=True shuffle=True pin_memory=False prefetch_factor=n/a persistent_workers=False
2025-10-31 23:22:27,105 INFO __main__: Created val dataset with training scalers
2025-10-31 23:22:27,106 INFO __main__: Loaded val data module | samples=139 batches=70 batch_size=2 drop_last=False shuffle=False pin_memory=False prefetch_factor=n/a persistent_workers=False
2025-10-31 23:22:27,521 INFO __main__: Created test dataset with training scalers
2025-10-31 23:22:27,521 INFO __main__: Loaded test data module | samples=39 batches=20 batch_size=2 drop_last=False shuffle=False pin_memory=False prefetch_factor=n/a persistent_workers=False
2025-10-31 23:22:27,522 INFO __main__: Data loader sizes | train=3401 val=70 test=20
2025-10-31 23:22:27,522 INFO __main__: Preparing scaling utilities for loss computation
2025-10-31 23:22:27,522 INFO __main__: Main scaler detected with 118 features
2025-10-31 23:22:27,522 INFO __main__: Target scaler detected with 4 features
2025-10-31 23:22:27,522 INFO __main__: Using target indices for OHLC: [0, 1, 2, 3]
2025-10-31 23:22:27,523 INFO __main__: Initializing production Celestial Enhanced PGAT model
2025-10-31 23:22:27,523 INFO models.Celestial_Enhanced_PGAT_Modular.Model: Initializing Celestial Enhanced PGAT | seq_len=96 pred_len=12 d_model=128 celestial_bodies=13 wave_aggregation=True mixture_decoder=True stochastic_learner=True hierarchical_mapping=True
2025-10-31 23:22:27,523 INFO models.Celestial_Enhanced_PGAT_Modular.Model: Phase-aware aggregation configured | input_waves=118 target_wave_indices=[0, 1, 2, 3]
2025-10-31 23:22:27,821 INFO models.celestial_modules.context_fusion: üåü Initializing Multi-Scale Context Fusion | mode=multi_scale | d_model=128
2025-10-31 23:22:27,821 INFO models.celestial_modules.context_fusion: üìä Multi-scale configuration | short=5 medium=15 long=global dropout=0.100
2025-10-31 23:22:27,823 INFO models.celestial_modules.context_fusion: ‚úÖ Multi-scale fusion layer initialized
2025-10-31 23:22:27,823 INFO models.celestial_modules.context_fusion: ‚ö° Performance: Small overhead (~8% memory increase, fast)
2025-10-31 23:22:27,824 INFO models.celestial_modules.context_fusion: üß† Benefits: Multi-temporal patterns, richest context, gradient flow enhancement
2025-10-31 23:22:27,824 INFO models.celestial_modules.context_fusion: üåä Gradient Flow: Creates shortcuts for long-term dependencies
2025-10-31 23:22:27,824 INFO models.celestial_modules.context_fusion: ‚öñÔ∏è  Bias Mitigation: Balances recent vs historical observations
2025-10-31 23:22:27,824 INFO models.celestial_modules.context_fusion: üîç Temporal Awareness: Provides both local dynamics and global context
2025-10-31 23:22:27,824 INFO models.celestial_modules.context_fusion: üéâ Multi-Scale Context Fusion successfully initialized
2025-10-31 23:22:27,875 ERROR __main__: Model initialization failed: d_model (128) must be divisible by num_graph_nodes (13) for efficient processing.
Traceback (most recent call last):
  File "/Users/shantanumisra/workspace/TSLib/Time-Series-Library/scripts/train/train_celestial_production.py", line 2491, in train_celestial_pgat_production
    model = Model(args).to(device)
            ^^^^^^^^^^^
  File "/Users/shantanumisra/workspace/TSLib/Time-Series-Library/models/Celestial_Enhanced_PGAT_Modular.py", line 92, in __init__
    self.graph_module = GraphModule(self.model_config)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/shantanumisra/workspace/TSLib/Time-Series-Library/models/celestial_modules/graph.py", line 118, in __init__
    raise ValueError(f"d_model ({config.d_model}) must be divisible by num_graph_nodes ({config.num_graph_nodes}) for efficient processing.")
ValueError: d_model (128) must be divisible by num_graph_nodes (13) for efficient processing.
