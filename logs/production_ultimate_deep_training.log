2025-10-29 14:05:47,870 | INFO     | __main__ | Starting PRODUCTION Celestial Enhanced PGAT training run
2025-10-29 14:05:47,871 | INFO     | __main__ | Heavy-duty overnight configuration enabled
2025-10-29 14:05:47,871 | INFO     | __main__ | üîç DIAGNOSTIC MODE ENABLED - Writing to training_diagnostic.log
2025-10-29 14:05:47,871 | INFO     | __main__ | ================================================================================
2025-10-29 14:05:47,872 | INFO     | __main__ | Memory diagnostics enabled; detailed logs stored at checkpoints\celestial_ultimate_deep_500x20\memory_diagnostics.log
2025-10-29 14:05:47,872 | INFO     | __main__ | Configuration summary | model=Celestial_Enhanced_PGAT seq_len=500 pred_len=20 d_model=780 n_heads=20 e_layers=12 d_layers=6 train_epochs=75
2025-10-29 14:05:47,872 | INFO     | __main__ | Optimization summary | batch_size=6 learning_rate=8e-05 patience=25 target=log_Open,log_High,log_Low,log_Close target_wave_indices=[0, 1, 2, 3] c_out=4 wave_aggregation=True
2025-10-29 14:05:47,872 | INFO     | __main__ | Using device: cpu (CPU fallback)
2025-10-29 14:05:47,876 | INFO     | __main__ | Reproducibility seed configured to 42
2025-10-29 14:05:47,876 | INFO     | __main__ | Loading production data modules
2025-10-29 14:05:48,081 | INFO     | __main__ | Training scalers extracted: main_scaler=True, target_scaler=True
2025-10-29 14:05:48,081 | INFO     | __main__ | Loaded train data module | samples=6390 batches=1065 batch_size=6 drop_last=True shuffle=True pin_memory=False prefetch_factor=6 persistent_workers=True
2025-10-29 14:05:48,260 | INFO     | __main__ | Created val dataset with training scalers
2025-10-29 14:05:48,261 | INFO     | __main__ | Loaded val data module | samples=81 batches=14 batch_size=6 drop_last=False shuffle=False pin_memory=False prefetch_factor=6 persistent_workers=True
2025-10-29 14:05:48,438 | INFO     | __main__ | Created test dataset with training scalers
2025-10-29 14:05:48,438 | INFO     | __main__ | Loaded test data module | samples=81 batches=14 batch_size=6 drop_last=False shuffle=False pin_memory=False prefetch_factor=6 persistent_workers=True
2025-10-29 14:05:48,438 | INFO     | __main__ | Data loader sizes | train=1065 val=14 test=14
2025-10-29 14:05:48,438 | INFO     | __main__ | Preparing scaling utilities for loss computation
2025-10-29 14:05:48,438 | INFO     | __main__ | Main scaler detected with 118 features
2025-10-29 14:05:48,439 | INFO     | __main__ | Target scaler detected with 4 features
2025-10-29 14:05:48,439 | INFO     | __main__ | Using target indices for OHLC: [0, 1, 2, 3]
2025-10-29 14:05:48,439 | INFO     | __main__ | Initializing production Celestial Enhanced PGAT model
2025-10-29 14:05:48,439 | INFO     | models.Celestial_Enhanced_PGAT_Modular.Model | Initializing Celestial Enhanced PGAT | seq_len=500 pred_len=20 d_model=780 celestial_bodies=13 wave_aggregation=True mixture_decoder=True stochastic_learner=True hierarchical_mapping=True
2025-10-29 14:05:48,439 | INFO     | models.Celestial_Enhanced_PGAT_Modular.Model | Phase-aware aggregation configured | input_waves=118 target_wave_indices=[0, 1, 2, 3]
2025-10-29 14:05:48,571 | INFO     | models.celestial_modules.context_fusion | üåü Initializing Multi-Scale Context Fusion | mode=multi_scale | d_model=780
2025-10-29 14:05:48,571 | INFO     | models.celestial_modules.context_fusion | üìä Multi-scale configuration | short=5 medium=25 long=125 dropout=0.100
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | ‚úÖ Multi-scale fusion layer initialized
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | ‚ö° Performance: Small overhead (~8% memory increase, fast)
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | üß† Benefits: Multi-temporal patterns, richest context, gradient flow enhancement
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | üåä Gradient Flow: Creates shortcuts for long-term dependencies
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | ‚öñÔ∏è  Bias Mitigation: Balances recent vs historical observations
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | üîç Temporal Awareness: Provides both local dynamics and global context
2025-10-29 14:05:48,624 | INFO     | models.celestial_modules.context_fusion | üéâ Multi-Scale Context Fusion successfully initialized
2025-10-29 14:05:52,817 | INFO     | __main__ | Model initialized successfully
2025-10-29 14:05:52,827 | INFO     | __main__ | Parameter statistics | total=307,283,346 trainable=307,283,346 approx_size_mb=1172.2
2025-10-29 14:05:52,835 | INFO     | __main__ | Standard precision training
2025-10-29 14:05:52,835 | INFO     | __main__ | Gradient accumulation configured | steps=3 effective_batch_size=18
2025-10-29 14:05:52,835 | INFO     | __main__ | Learning rate schedule preview | warmup_epochs=8 base_lr=0.000080 min_lr=0.000000 remaining_epochs=67
2025-10-29 14:05:52,836 | INFO     | __main__ | Sample learning rates: E1:0.000010, E8:0.000080, E9:0.000080, E38:0.000048, E75:0.000000
2025-10-29 14:05:52,839 | INFO     | __main__ | Using Hybrid MDN+Directional Loss | nll_weight=0.30 direction_weight=3.00 trend_weight=1.50 magnitude_weight=0.10
2025-10-29 14:05:52,839 | INFO     | __main__ | Early stopping patience configured to 25 (effectively disabled)
2025-10-29 14:05:52,839 | INFO     | __main__ | Checkpoints will be saved to checkpoints\celestial_ultimate_deep_500x20
2025-10-29 14:05:52,839 | INFO     | __main__ | Inspecting data file at ./data\prepared_financial_data.csv for target resolution
2025-10-29 14:05:52,847 | INFO     | __main__ | Feature summary | total_columns=119 feature_columns=118
2025-10-29 14:05:52,877 | INFO     | __main__ | Estimated CSV row count: 7109
2025-10-29 14:05:52,878 | INFO     | __main__ | Auto-set enc_in/dec_in to 118 based on feature count
2025-10-29 14:05:52,878 | INFO     | __main__ | Resolved target indices: [0, 1, 2, 3]
2025-10-29 14:05:52,878 | INFO     | __main__ | Resolved target names: ['log_Open', 'log_High', 'log_Low', 'log_Close']
2025-10-29 14:05:52,878 | INFO     | __main__ | Starting production training loop
2025-10-29 14:05:52,878 | INFO     | __main__ | Configured for 75 training epochs
2025-10-29 14:05:52,879 | INFO     | __main__ | Warmup phase | epoch=1/8 lr=0.00001000
2025-10-29 14:05:52,889 | INFO     | __main__ | Epoch 1/75 - production training
2025-10-29 14:27:53,009 | INFO     | __main__ | Starting PRODUCTION Celestial Enhanced PGAT training run
2025-10-29 14:27:53,010 | INFO     | __main__ | Heavy-duty overnight configuration enabled
2025-10-29 14:27:53,010 | INFO     | __main__ | üîç DIAGNOSTIC MODE ENABLED - Writing to training_diagnostic.log
2025-10-29 14:27:53,010 | INFO     | __main__ | ================================================================================
2025-10-29 14:27:53,012 | INFO     | __main__ | Memory diagnostics enabled; detailed logs stored at checkpoints\celestial_ultimate_deep_500x20\memory_diagnostics.log
2025-10-29 14:27:53,012 | INFO     | __main__ | Configuration summary | model=Celestial_Enhanced_PGAT seq_len=500 pred_len=20 d_model=780 n_heads=20 e_layers=12 d_layers=6 train_epochs=75
2025-10-29 14:27:53,012 | INFO     | __main__ | Optimization summary | batch_size=6 learning_rate=8e-05 patience=25 target=log_Open,log_High,log_Low,log_Close target_wave_indices=[0, 1, 2, 3] c_out=4 wave_aggregation=True
2025-10-29 14:27:53,012 | INFO     | __main__ | Using device: cpu (CPU fallback)
2025-10-29 14:27:53,017 | INFO     | __main__ | Reproducibility seed configured to 42
2025-10-29 14:27:53,018 | INFO     | __main__ | Loading production data modules
2025-10-29 14:27:53,233 | INFO     | __main__ | Training scalers extracted: main_scaler=True, target_scaler=True
2025-10-29 14:27:53,233 | INFO     | __main__ | Loaded train data module | samples=6390 batches=1065 batch_size=6 drop_last=True shuffle=True pin_memory=False prefetch_factor=6 persistent_workers=True
2025-10-29 14:27:53,405 | INFO     | __main__ | Created val dataset with training scalers
2025-10-29 14:27:53,405 | INFO     | __main__ | Loaded val data module | samples=81 batches=14 batch_size=6 drop_last=False shuffle=False pin_memory=False prefetch_factor=6 persistent_workers=True
2025-10-29 14:27:53,580 | INFO     | __main__ | Created test dataset with training scalers
2025-10-29 14:27:53,581 | INFO     | __main__ | Loaded test data module | samples=81 batches=14 batch_size=6 drop_last=False shuffle=False pin_memory=False prefetch_factor=6 persistent_workers=True
2025-10-29 14:27:53,581 | INFO     | __main__ | Data loader sizes | train=1065 val=14 test=14
2025-10-29 14:27:53,581 | INFO     | __main__ | Preparing scaling utilities for loss computation
2025-10-29 14:27:53,581 | INFO     | __main__ | Main scaler detected with 118 features
2025-10-29 14:27:53,581 | INFO     | __main__ | Target scaler detected with 4 features
2025-10-29 14:27:53,582 | INFO     | __main__ | Using target indices for OHLC: [0, 1, 2, 3]
2025-10-29 14:27:53,582 | INFO     | __main__ | Initializing production Celestial Enhanced PGAT model
2025-10-29 14:27:53,582 | INFO     | models.Celestial_Enhanced_PGAT_Modular.Model | Initializing Celestial Enhanced PGAT | seq_len=500 pred_len=20 d_model=780 celestial_bodies=13 wave_aggregation=True mixture_decoder=True stochastic_learner=True hierarchical_mapping=True
2025-10-29 14:27:53,582 | INFO     | models.Celestial_Enhanced_PGAT_Modular.Model | Phase-aware aggregation configured | input_waves=118 target_wave_indices=[0, 1, 2, 3]
2025-10-29 14:27:53,724 | INFO     | models.celestial_modules.context_fusion | üåü Initializing Multi-Scale Context Fusion | mode=multi_scale | d_model=780
2025-10-29 14:27:53,724 | INFO     | models.celestial_modules.context_fusion | üìä Multi-scale configuration | short=5 medium=25 long=125 dropout=0.100
2025-10-29 14:27:53,764 | INFO     | models.celestial_modules.context_fusion | ‚úÖ Multi-scale fusion layer initialized
2025-10-29 14:27:53,764 | INFO     | models.celestial_modules.context_fusion | ‚ö° Performance: Small overhead (~8% memory increase, fast)
2025-10-29 14:27:53,765 | INFO     | models.celestial_modules.context_fusion | üß† Benefits: Multi-temporal patterns, richest context, gradient flow enhancement
2025-10-29 14:27:53,765 | INFO     | models.celestial_modules.context_fusion | üåä Gradient Flow: Creates shortcuts for long-term dependencies
2025-10-29 14:27:53,765 | INFO     | models.celestial_modules.context_fusion | ‚öñÔ∏è  Bias Mitigation: Balances recent vs historical observations
2025-10-29 14:27:53,765 | INFO     | models.celestial_modules.context_fusion | üîç Temporal Awareness: Provides both local dynamics and global context
2025-10-29 14:27:53,765 | INFO     | models.celestial_modules.context_fusion | üéâ Multi-Scale Context Fusion successfully initialized
2025-10-29 14:27:57,804 | INFO     | __main__ | Model initialized successfully
2025-10-29 14:27:57,815 | INFO     | __main__ | Parameter statistics | total=307,283,346 trainable=307,283,346 approx_size_mb=1172.2
2025-10-29 14:27:57,822 | INFO     | __main__ | Standard precision training
2025-10-29 14:27:57,822 | INFO     | __main__ | Gradient accumulation configured | steps=3 effective_batch_size=18
2025-10-29 14:27:57,822 | INFO     | __main__ | Learning rate schedule preview | warmup_epochs=8 base_lr=0.000080 min_lr=0.000000 remaining_epochs=67
2025-10-29 14:27:57,822 | INFO     | __main__ | Sample learning rates: E1:0.000010, E8:0.000080, E9:0.000080, E38:0.000048, E75:0.000000
2025-10-29 14:27:57,826 | INFO     | __main__ | Using Hybrid MDN+Directional Loss | nll_weight=0.25 direction_weight=4.00 trend_weight=2.00 magnitude_weight=0.15
2025-10-29 14:27:57,826 | INFO     | __main__ | Early stopping patience configured to 25 (effectively disabled)
2025-10-29 14:27:57,826 | INFO     | __main__ | Checkpoints will be saved to checkpoints\celestial_ultimate_deep_500x20
2025-10-29 14:27:57,826 | INFO     | __main__ | Inspecting data file at ./data\prepared_financial_data.csv for target resolution
2025-10-29 14:27:57,833 | INFO     | __main__ | Feature summary | total_columns=119 feature_columns=118
2025-10-29 14:27:57,862 | INFO     | __main__ | Estimated CSV row count: 7109
2025-10-29 14:27:57,862 | INFO     | __main__ | Auto-set enc_in/dec_in to 118 based on feature count
2025-10-29 14:27:57,862 | INFO     | __main__ | Resolved target indices: [0, 1, 2, 3]
2025-10-29 14:27:57,862 | INFO     | __main__ | Resolved target names: ['log_Open', 'log_High', 'log_Low', 'log_Close']
2025-10-29 14:27:57,862 | INFO     | __main__ | Starting production training loop
2025-10-29 14:27:57,862 | INFO     | __main__ | Configured for 75 training epochs
2025-10-29 14:27:57,863 | INFO     | __main__ | Warmup phase | epoch=1/8 lr=0.00001000
2025-10-29 14:27:57,877 | INFO     | __main__ | Epoch 1/75 - production training
